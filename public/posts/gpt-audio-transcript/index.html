<!DOCTYPE html>
<html lang="en">
    <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="">
<meta name="description" content="Hi there ðŸ‘½!
In this article I wanted to do a quick demonstration on how to integrate with OpenAI Whipser model to transcript an audio file, using Typescript and ffmpeg.
In my repo you have the full code of the script that I made for this article, as well as instructions on how to use it as is.
Let&amp;rsquo;s get started!
OpenAI integration I decided to integrate with OpenAI using a HTTP client (axios in this case) directly." />
<meta name="keywords" content=", Nightly Dev Notes" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="" />
<link rel="canonical" href="http://localhost:1313/posts/gpt-audio-transcript/" />


    <title>
        
            [NDN] Transcript audio to text using OpenAI Whisper :: NightlyDev 
        
    </title>





<link rel="stylesheet" href="/main.017c30ecf94dbed4078cd1c910e4fc01d2c2ac071a9e9d7c143786493e367eb5.css" integrity="sha256-AXww7PlNvtQHjNHJEOT8AdLCrAcanp18FDeGST42frU=">




<link rel="stylesheet" href="/css/syntax.css">

    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="">
    <link rel="shortcut icon" href="/favicon.ico">
    <meta name="msapplication-TileColor" content="">



  <meta itemprop="name" content="[NDN] Transcript audio to text using OpenAI Whisper">
  <meta itemprop="description" content="Hi there ðŸ‘½!
In this article I wanted to do a quick demonstration on how to integrate with OpenAI Whipser model to transcript an audio file, using Typescript and ffmpeg.
In my repo you have the full code of the script that I made for this article, as well as instructions on how to use it as is.
Letâ€™s get started!
OpenAI integration I decided to integrate with OpenAI using a HTTP client (axios in this case) directly.">
  <meta itemprop="datePublished" content="2024-06-30T00:57:02+02:00">
  <meta itemprop="dateModified" content="2024-06-30T00:57:02+02:00">
  <meta itemprop="wordCount" content="869">
  <meta itemprop="keywords" content="Nightly Dev Notes">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="[NDN] Transcript audio to text using OpenAI Whisper">
  <meta name="twitter:description" content="Hi there ðŸ‘½!
In this article I wanted to do a quick demonstration on how to integrate with OpenAI Whipser model to transcript an audio file, using Typescript and ffmpeg.
In my repo you have the full code of the script that I made for this article, as well as instructions on how to use it as is.
Letâ€™s get started!
OpenAI integration I decided to integrate with OpenAI using a HTTP client (axios in this case) directly.">







    <meta property="article:published_time" content="2024-06-30 00:57:02 &#43;0200 CEST" />











    </head>

    
        <body>
    
    
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="/" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">></span>
            <span class="logo__text ">
                NightlyDev</span>
            <span class="logo__cursor" style=
                  "
                   
                   ">
            </span>
        
    </div>
</a>


        <span class="header__right">
            
                <nav class="menu">
    <ul class="menu__inner"><li><a href="/about">About</a></li><li><a href="/posts">Blog</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
            
                <span class="theme-toggle not-selectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
   <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
   3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
   13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
 </svg></span>
        </span>
    </span>
</header>


            <div class="content">
                
  <main class="post">

    <div class="post-info">
      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock">
          <circle cx="12" cy="12" r="10"></circle>
          <polyline points="12 6 12 12 16 14"></polyline>
        </svg>
        5 minutes

        
      </p>
    </div>

    <article>
      <h1 class="post-title">
        <a href="http://localhost:1313/posts/gpt-audio-transcript/">[NDN] Transcript audio to text using OpenAI Whisper</a>
      </h1>

      

      

      

      <div class="post-content">
        <p>Hi there ðŸ‘½!</p>
<p>In this article I wanted to do a quick demonstration on how to integrate with <strong>OpenAI Whipser</strong> model to transcript an audio file, using <strong>Typescript</strong> and <strong>ffmpeg</strong>.</p>
<p>In my <a href="https://github.com/Alchemistst/gpt-audio-transcript">repo</a> you have the full code of the script that I made for this article, as well as instructions on how to use it as is.</p>
<p>Let&rsquo;s get started!</p>
<h2 id="openai-integration">OpenAI integration</h2>
<p>I decided to integrate with OpenAI using a HTTP client (axios in this case) directly.
The way you have to structure the request is not too complicated, but you must pay attention to a couple of details:</p>
<ol>
<li>It has to be a POST operation to <code>https://api.openai.com/v1/audio/transcriptions</code></li>
<li>The body <em>Content Type</em> has to be of type <code>multipart/form-data</code> and has to have the following fields:
<ul>
<li><code>model</code>: which specifies the model to use.</li>
<li><code>file</code>: expects a <a href="https://developer.mozilla.org/en-US/docs/Web/API/Blob">Blob</a> of your audio.</li>
<li><code>language</code>: not required, but I had the best results when sending it. Must follow the <a href="https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes">ISO-639</a> standard.</li>
</ul>
</li>
<li>As authorization headers, you must pass your OpenAI API key.
Here&rsquo;s the code for just the OpenAI integration:</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Typescript" data-lang="Typescript"><span class="line"><span class="cl"> <span class="kr">const</span> <span class="nx">formData</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">FormData</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">  <span class="nx">formData</span><span class="p">.</span><span class="nx">append</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;file&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="k">new</span> <span class="nx">Blob</span><span class="p">([</span><span class="k">await</span> <span class="nx">fs</span><span class="p">.</span><span class="nx">promises</span><span class="p">.</span><span class="nx">readFile</span><span class="p">(</span><span class="nx">filePath</span><span class="p">)]),</span>
</span></span><span class="line"><span class="cl">    <span class="nx">filePath</span><span class="p">.</span><span class="nx">replace</span><span class="p">(</span><span class="nx">outputDirectory</span><span class="p">,</span> <span class="s2">&#34;&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="nx">formData</span><span class="p">.</span><span class="nx">append</span><span class="p">(</span><span class="s2">&#34;model&#34;</span><span class="p">,</span> <span class="s2">&#34;whisper-1&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="nx">formData</span><span class="p">.</span><span class="nx">append</span><span class="p">(</span><span class="s2">&#34;language&#34;</span><span class="p">,</span> <span class="nx">language</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">try</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kr">const</span> <span class="nx">response</span> <span class="o">=</span> <span class="k">await</span> <span class="nx">axios</span><span class="p">.</span><span class="nx">post</span><span class="p">(</span><span class="nx">speechToTextAPI</span><span class="p">,</span> <span class="nx">formData</span><span class="p">,</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="nx">headers</span><span class="o">:</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;Content-Type&#34;</span><span class="o">:</span> <span class="s2">&#34;multipart/form-data&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="nx">Authorization</span><span class="o">:</span> <span class="sb">`Bearer </span><span class="si">${</span><span class="nx">apiKey</span><span class="si">}</span><span class="sb">`</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">      <span class="p">},</span>
</span></span><span class="line"><span class="cl">    <span class="p">});</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="nx">response</span><span class="p">.</span><span class="nx">data</span><span class="p">.</span><span class="nx">text</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span> <span class="k">catch</span> <span class="p">(</span><span class="nx">error</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="nx">console</span><span class="p">.</span><span class="nx">error</span><span class="p">(</span><span class="sb">`Error transcribing </span><span class="si">${</span><span class="nx">filePath</span><span class="si">}</span><span class="sb">:`</span><span class="p">,</span> <span class="nx">error</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="kc">null</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span></code></pre></div><p>This is by no means an exhaustive description of all the API&rsquo;s capabilities. Find more info of all its potential <a href="https://platform.openai.com/docs/guides/speech-to-text">here</a>.</p>
<h2 id="audio-file-processing">Audio file processing</h2>
<p>Okay, so we already know how to integrate with OpenAI to send our audio and get its transcription. But now we need a way to get the audio from our computer, load it to the script, and then get the results. Easy, right?</p>
<p>Well&hellip; There are a couple of caveats.</p>
<p>First, the aforementioned endpoint <strong>can only process chunks of 5 min of audio</strong>, so if we want to transcript a longer audio, we&rsquo;ll need to chop the audio first in chunks no longer than 5 min.</p>
<p>For this task I decided to use <code>fluent-ffmpeg</code>, a Typescrypt wrapper for ffmpeg, to process audio. The problem here is that, the way ffmpeg chops and process de audio in parallel, doesn&rsquo;t ensure the order of the chops will be maintained.</p>
<p>Plus, as soon as each chop is loaded, it will call OpenAI to get its transcription, and this is also an <em>asynchronous operation</em>, meaning that some requests may take more time than others, messing even more with the order of the chops.</p>
<p>In order to get a coherent transcription, we have to get a reference to the order in which the chops need to be, then send that to OpenAI without loosing these references, so that when we get all the responses from all the audio chops, we can place them back together in the original order and the transcription makes sense.</p>
<p>So, this was my solution:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Typescript" data-lang="Typescript"><span class="line"><span class="cl"><span class="kr">const</span> <span class="nx">inputFileName</span> <span class="o">=</span> <span class="nx">path</span><span class="p">.</span><span class="nx">basename</span><span class="p">(</span><span class="nx">filePath</span><span class="p">,</span> <span class="nx">path</span><span class="p">.</span><span class="nx">extname</span><span class="p">(</span><span class="nx">filePath</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">  <span class="nx">Ffmpeg</span><span class="p">.</span><span class="nx">ffprobe</span><span class="p">(</span><span class="nx">filePath</span><span class="p">,</span> <span class="p">(</span><span class="nx">err</span><span class="p">,</span> <span class="nx">metadata</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="nx">err</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="nx">console</span><span class="p">.</span><span class="nx">error</span><span class="p">(</span><span class="s2">&#34;Error getting metadata:&#34;</span><span class="p">,</span> <span class="nx">err</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">      <span class="k">return</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kr">const</span> <span class="nx">totalDuration</span> <span class="o">=</span> <span class="nx">metadata</span><span class="p">.</span><span class="nx">format</span><span class="p">.</span><span class="nx">duration</span> <span class="o">??</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kr">const</span> <span class="nx">numberOfSegments</span> <span class="o">=</span> <span class="nb">Math</span><span class="p">.</span><span class="nx">ceil</span><span class="p">(</span><span class="nx">totalDuration</span> <span class="o">/</span> <span class="nx">duration</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kd">let</span> <span class="nx">transcript</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Map</span><span class="p">&lt;</span><span class="nt">number</span><span class="err">,</span> <span class="na">string</span><span class="p">&gt;();</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kr">const</span> <span class="nx">finishCallback</span> <span class="o">=</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="kr">const</span> <span class="nx">outputFileName</span> <span class="o">=</span> <span class="nx">path</span><span class="p">.</span><span class="nx">join</span><span class="p">(</span><span class="nx">outputDir</span><span class="p">,</span> <span class="sb">`</span><span class="si">${</span><span class="nx">inputFileName</span><span class="si">}</span><span class="sb">.txt`</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">      <span class="kd">let</span> <span class="nx">output</span> <span class="o">=</span> <span class="s2">&#34;&#34;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">      <span class="k">for</span> <span class="p">(</span><span class="kd">let</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">numberOfSegments</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nx">output</span> <span class="o">=</span> <span class="sb">`</span><span class="si">${</span><span class="nx">output</span><span class="si">}</span><span class="sb"> </span><span class="si">${</span><span class="nx">transcript</span><span class="p">.</span><span class="kr">get</span><span class="p">(</span><span class="nx">i</span><span class="p">)</span><span class="si">}</span><span class="sb">`</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">      <span class="p">}</span>
</span></span><span class="line"><span class="cl">      <span class="nx">fs</span><span class="p">.</span><span class="nx">writeFileSync</span><span class="p">(</span><span class="nx">outputFileName</span><span class="p">,</span> <span class="nx">output</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">      <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="s2">&#34;Transcript saved to &#34;</span> <span class="o">+</span> <span class="nx">outputFileName</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">};</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kd">let</span> <span class="nx">finishCount</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kd">let</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">numberOfSegments</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="kr">const</span> <span class="nx">startTime</span> <span class="o">=</span> <span class="nx">i</span> <span class="o">*</span> <span class="nx">duration</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">      <span class="kr">const</span> <span class="nx">outputFileName</span> <span class="o">=</span> <span class="nx">path</span><span class="p">.</span><span class="nx">join</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="nx">outputDir</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="sb">`</span><span class="si">${</span><span class="nx">inputFileName</span><span class="si">}</span><span class="sb">_part_</span><span class="si">${</span><span class="nx">i</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="sb">.mp3`</span>
</span></span><span class="line"><span class="cl">      <span class="p">);</span>
</span></span><span class="line"><span class="cl">      <span class="nx">Ffmpeg</span><span class="p">(</span><span class="nx">filePath</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="p">.</span><span class="nx">setStartTime</span><span class="p">(</span><span class="nx">startTime</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="p">.</span><span class="nx">setDuration</span><span class="p">(</span><span class="nx">duration</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="p">.</span><span class="nx">output</span><span class="p">(</span><span class="nx">outputFileName</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="p">.</span><span class="nx">on</span><span class="p">(</span><span class="s2">&#34;end&#34;</span><span class="p">,</span> <span class="kr">async</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">          <span class="kr">const</span> <span class="nx">partialTranscript</span> <span class="o">=</span> <span class="k">await</span> <span class="nx">sendToSpeechToText</span><span class="p">(</span><span class="nx">outputFileName</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">          <span class="k">if</span> <span class="p">(</span><span class="nx">partialTranscript</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="nx">transcript</span><span class="p">.</span><span class="kr">set</span><span class="p">(</span><span class="nx">i</span><span class="p">,</span> <span class="nx">partialTranscript</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">          <span class="p">}</span>
</span></span><span class="line"><span class="cl">          <span class="nx">finishCount</span><span class="o">++</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">          <span class="k">if</span> <span class="p">(</span><span class="nx">finishCount</span> <span class="o">===</span> <span class="nx">numberOfSegments</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="nx">finishCallback</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">          <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="p">})</span>
</span></span><span class="line"><span class="cl">        <span class="p">.</span><span class="nx">on</span><span class="p">(</span><span class="s2">&#34;error&#34;</span><span class="p">,</span> <span class="p">(</span><span class="nx">err</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">          <span class="nx">console</span><span class="p">.</span><span class="nx">error</span><span class="p">(</span><span class="s2">&#34;Error processing segment:&#34;</span><span class="p">,</span> <span class="nx">err</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="p">})</span>
</span></span><span class="line"><span class="cl">        <span class="p">.</span><span class="nx">run</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">  <span class="p">});</span>
</span></span></code></pre></div><p>To solve the problem of asynchronicity (if that&rsquo;s even word), we calculate first the <code>numberOfSegments</code> the audio is going to result. Then, the audio gets chopped in that many segments, and every time a chop is processed, we store its position <code>i</code> and its transcription in the <code>transcript</code> map.</p>
<p>After all this, we increase the <code>finishCount</code> variable, and if it is less than the <code>numberOfSegments</code> that means that we are still waiting for some of the audio files to get processed.
But, if <code>finishCount</code> it&rsquo;s equal to <code>numberOfSegments</code>, that means that all the chops where processed and we are ready to put everything together.</p>
<p>And that&rsquo;s what we do in <code>finishCallback()</code>, we access all the keys in order, joining all the partial transcripts.</p>
<p>Hooray! We have our transcript! ðŸ¥³</p>
<h2 id="conclusion">Conclusion</h2>
<p>As you have seen, interacting with OpenAI API and process audio wasn&rsquo;t that difficult, was it?</p>
<p>For sure this script has a lot of room for optimization. For instance, chopping the audio with this method creates little artifacts on the audio files, that show on the transcript as a result, due to being cut off in the middle of a sentence or word. This could be fixed trying to align the chops with silences in the audio (still not perfect, but might be an improvement).</p>
<p>In any case, I hope you have found this post useful or inspiring to go out there and get coding.</p>
<p>For now, this is all.
Signing out&hellip;</p>

      </div>
    </article>

    <hr />

    <div class="post-info">
      
    <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg>

        <span class="tag"><a href="http://localhost:1313/tags/nightly-dev-notes/">Nightly Dev Notes</a></span>
        
    </p>

      

      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text">
          <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path>
          <polyline points="14 2 14 8 20 8"></polyline>
          <line x1="16" y1="13" x2="8" y2="13"></line>
          <line x1="16" y1="17" x2="8" y2="17"></line>
          <polyline points="10 9 9 9 8 9"></polyline>
        </svg>
        869 Words
      </p>

      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar">
          <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect>
          <line x1="16" y1="2" x2="16" y2="6"></line>
          <line x1="8" y1="2" x2="8" y2="6"></line>
          <line x1="3" y1="10" x2="21" y2="10"></line>
        </svg>
        
          2024-06-30 00:57
        

         
          
        
      </p>
    </div>

    
    <div class="pagination">
        

        <div class="pagination__buttons">
            

            
            <span class="button next">
                <a href="http://localhost:1313/posts/crud-graphql/">
                    <span class="button__text">[NDN] Building a simple CRUD using GraphQL</span>
                    <span class="button__icon">â†’</span>
                </a>
            </span>
            
        </div>
    </div>


    

    

    

  </main>

            </div>

            
                <footer class="footer">
    
    
</footer>

            
        </div>

        


<script type="text/javascript" src="/bundle.min.4037dc94fd1565c4fd3354e2b4a2d1ff11842c906242435350b4d2d8d6e8b7890da46c0a865173f543a6161c1f4d1c94147f1b907db36489fc2bf5e20d4af75c.js" integrity="sha512-QDfclP0VZcT9M1TitKLR/xGELJBiQkNTULTS2Nbot4kNpGwKhlFz9UOmFhwfTRyUFH8bkH2zZIn8K/XiDUr3XA=="></script>




    </body>
</html>
